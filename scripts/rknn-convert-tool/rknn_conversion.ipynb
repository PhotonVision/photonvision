{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63e2692b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb5367ce",
   "metadata": {},
   "source": [
    "# RKNN Conversion Guide\n",
    "\n",
    "----------------------------\n",
    "\n",
    "### Before you start\n",
    "\n",
    "Before you run the scripts/python notebook from this project, it's recommended you create a separate [python virtual environment](https://docs.python.org/3/library/venv.html) so that packages installed for the conversion process don't conflict with other packages you may already have installed.\n",
    "\n",
    "\n",
    "### Preinstallation (for Google Colab users)\n",
    "\n",
    "This notebook requires the use of external python scripts, please run this snippet with the URL (`GITHUB_URL`) to the Photonvision repo, if not provided already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_URL = \"https://github.com/PhotonVision/photonvision\"\n",
    "SCRIPTS_FOLDER = \"/scripts/rknn-convert-tool\"\n",
    "\n",
    "import sys\n",
    "from urllib.parse import urlparse\n",
    "import subprocess\n",
    "\n",
    "parsed = urlparse(GITHUB_URL)\n",
    "        \n",
    "if parsed.netloc.lower() not in ['github.com', 'www.github.com']:\n",
    "   print(\"URL must be GitHub URL!\")\n",
    "   sys.exit(1)\n",
    "            \n",
    "path_parts = parsed.path.strip('/').split('/')\n",
    "        \n",
    "if len(path_parts) < 2:\n",
    "   print(\"Invalid Github URL! Must have org and repo in url\")\n",
    "   sys.exit(1)\n",
    "            \n",
    "org_user = path_parts[0]\n",
    "repo = path_parts[1]\n",
    "        \n",
    "if not org_user or not repo:\n",
    "   print(\"Invalid Github URL! Must have org and repo in url\")\n",
    "   sys.exit(1)\n",
    "            \n",
    "repo_sub_url = f\"{org_user}/{repo}\"\n",
    "folder_url = SCRIPTS_FOLDER.strip(\"/\")\n",
    "\n",
    "create_onnx_raw_url = f\"https://raw.githubusercontent.com/{repo_sub_url}/refs/heads/main/{folder_url}/create_onnx.py\"\n",
    "auto_install_script_raw_url = f\"https://raw.githubusercontent.com/{repo_sub_url}/refs/heads/main/{folder_url}/autoinstallrknnapi.py\"\n",
    "create_rknn_raw_url = f\"https://raw.githubusercontent.com/{repo_sub_url}/refs/heads/main/{folder_url}/create_rknn.py\"\n",
    "\n",
    "scriptUrls = [create_onnx_raw_url, auto_install_script_raw_url, create_rknn_raw_url]\n",
    "\n",
    "for scriptUrl in scriptUrls:\n",
    "    try:\n",
    "        subprocess.run([\"wget\", scriptUrl]).check_returncode()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to run script download for url {scriptUrl}\")\n",
    "        print(e.output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498ed79",
   "metadata": {},
   "source": [
    "### Step 1: Convert to ONNX \n",
    "\n",
    "To convert to ONNX, simply run the `create_onnx.py` script with your model weights, see below"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### *Notice for Colab users*\n",
    "\n",
    "Google Colab comes with an incompatible version of Numpy installed. To fix this, please run the following cells below and **restart your session** when prompted."
   ],
   "id": "d68be4aba4d3022b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%pip uninstall numpy -y\n",
    "%pip install \"numpy>=1.23.0,<2.0.0\""
   ],
   "id": "de0310a3e4401233",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then, simply run the `create_onnx.py` script to convert your `.pt` weights",
   "id": "341c6ff84cb88885"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where version is either yolov5, yolov8, or yolov11, and model_path is the path to your weights file (.pt)\n",
    "%run create_onnx.py --version yolov8 --model_path weights.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff07e6",
   "metadata": {},
   "source": [
    "### Step 2: Download RKNN API\n",
    "You can either utilize a script to autodetect and install the correct Python library for you, or manually install it\n",
    "\n",
    "#### Automatic installation\n",
    "Simply run the `autoinstallrknnapi.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec11f96",
   "metadata": {},
   "outputs": [],
   "source": "%run autoinstallrknnapi.py"
  },
  {
   "cell_type": "markdown",
   "id": "8b57fe4d",
   "metadata": {},
   "source": [
    "#### Manual installation\n",
    "##### How to find the correct link\n",
    "Go to https://github.com/airockchip/rknn-toolkit2, and click on `rknn-toolkit2`, then `packages`.\n",
    "If you are running an x86_64 CPU (e.g. most Intel and AMD CPUs) click on that, otherwise choose arm64 for ARM-based computers (e.g. M-series Macs or Snapdragon processors). If you aren't sure what CPU you are running, look up your processor architecture information from system settings.\n",
    "\n",
    "Once you have the correct CPU, you will see multiple packages. The file names will look something like `rknn_toolkit2-2.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl` for example. The numbers after CP correspond to your python version. If you have a Python version 3.10, for example, you want to download a package with cp310 in the name. For 3.8, you'd look for cp38, for 3.7 cp37, and so on.\n",
    "\n",
    "Then, once you find your desired package, locate the \"Raw\" download button, and download the package (.whl) once you do, run pip install, replacing `rknn_toolkit2.whl` with the path to the wheel file you just downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install rknn_toolkit2.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1db5ef0",
   "metadata": {},
   "source": [
    "### Step 3: Convert to RKNN\n",
    "\n",
    "Simply run the `create_rknn.py` script, replacing the arguments with your own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e431b",
   "metadata": {},
   "source": [
    "#### Overview of `create_rknn.py` script\n",
    "\n",
    "##### RKNN Conversion Script Overview\n",
    "\n",
    "This script converts a YOLO ONNX model to RKNN format using a set of calibration images. It's designed to work with either:\n",
    "\n",
    "- A flat directory of images (e.g. `train/images`), **or**\n",
    "- A dataset directory containing a `data.yaml` file that defines `train`, `val`, and/or `test` folders.\n",
    "\n",
    "You can use it from the command line or from inside a Python environment like this notebook.\n",
    "\n",
    "##### Arguments\n",
    "\n",
    "| Argument | Type | Description |\n",
    "|----------|------|-------------|\n",
    "| `--img_dir` (`-d`) | `str` (required) | Path to your image directory. This can either be a folder of images **or** a dataset folder with a `data.yaml`. |\n",
    "| `--model_path` (`-m`) | `str` (required) | Path to your YOLO ONNX model, created in Step 1. |\n",
    "| `--num_imgs` (`-ni`) | `int` (default: `300`) | Number of images to use for quantization calibration. |\n",
    "| `--disable_quantize` (`-dq`) | `bool` (default: `False`) | Set to `True` to skip quantization entirely, not recommended for performance. |\n",
    "| `--rknn_output` (`-o`) | `str` (default: `out.rknn`) | File path where the final RKNN model should be saved. |\n",
    "| `--img_dataset_txt` (`-ds`) | `str` (default: `imgs.txt`) | File path to store the list of images used during quantization. |\n",
    "| `--verbose` (`-vb`) | `bool` (default: `False`) | Enable detailed logging from RKNN during conversion. |\n",
    "---\n",
    "\n",
    "\n",
    "##### Notes\n",
    "\n",
    "As this is meant to be used with [PhotonVision](https://photonvision.org) this script only allows the target platform to be RK3588 (found in Orange Pi 5 models), but feel free to modify the script to suit your needs"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Quantization Note\n",
    "\n",
    "When performing quantization, it is critical to provide representative images of the objects or scenes you are trying to detect. These images are used to calibrate the model’s internal activations and greatly influence the final performance.\n",
    "\n",
    "It is recommended to use 300–500 representative images that reflect the real-world input your model will encounter. As the old saying goes, *quality* over quantity.\n",
    "\n",
    "Quantization will cause some loss in model accuracy. However, if your calibration images are chosen wisely, this accuracy drop should be minimal and acceptable. If the sampled images are too uniform or unrelated, your quantized model's performance may worsen significantly.\n",
    "\n",
    "The script will automatically sample representative images randomly from the provided dataset. While this usually works well, please verify that the dataset contains diverse and relevant examples of your target objects. As a reminder, the images used to quantize the model are stored in the text file specified by `--img_dataset_txt`.\n"
   ],
   "id": "5e56b2f64bf6e85f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Optional: Download a dataset from Roboflow for quantization\n",
    "\n",
    "Please run the below code to download a dataset from roboflow if you do not have an images to use for quantization. Feel free to replace the link in quotes with a link to your own dataset."
   ],
   "id": "93e0d0622df170e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%wget -O roboflow.zip \"https://universe.roboflow.com/ds/FaF3HbDmF7?key=iMoJR25O9H\" && unzip roboflow.zip -d datasets && rm roboflow.zip",
   "id": "8bf75c9dcb328c84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once you have your dataset prepared, run the below script to quantize and convert your generated ONNX model from Step 1.",
   "id": "81af402f3a94679a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09656dd",
   "metadata": {},
   "outputs": [],
   "source": "%run create_rknn.py --img_dir ./datasets --model_path weights.onnx"
  },
  {
   "cell_type": "markdown",
   "id": "5b3a6806",
   "metadata": {},
   "source": [
    "And that's it! You should have an RKNN model file ready to deploy on an Orange PI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
