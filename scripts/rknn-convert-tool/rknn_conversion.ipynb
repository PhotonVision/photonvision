{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb5367ce",
   "metadata": {},
   "source": [
    "# RKNN Conversion Guide\n",
    "\n",
    "----------------------------\n",
    "\n",
    "### Before you start\n",
    "\n",
    "Before you run the scripts or Python notebook from this project, it is recommended that you create a separate [Python virtual environment](https://docs.python.org/3/library/venv.html) so that the packages installed for the conversion process do not conflict with other packages you may already have installed.\n",
    "\n",
    "## Preinstallation — Important Setup for Google Colab Users\n",
    "\n",
    "This notebook requires the use of external Python scripts. Please run this snippet with the URL (GITHUB_URL) to the Photonvision repository, if it has not already been provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_URL = \"https://github.com/boomermath/photonvision_rknn_fork/tree/f0ed73c765c935d13466639713a4331d8425e546\"\n",
    "SCRIPTS_FOLDER = \"/scripts/rknn-convert-tool\"\n",
    "\n",
    "import sys\n",
    "from urllib.parse import urlparse\n",
    "import subprocess\n",
    "\n",
    "parsed = urlparse(GITHUB_URL)\n",
    "\n",
    "if parsed.netloc.lower() not in ['github.com', 'www.github.com']:\n",
    "    print(\"URL must be a GitHub URL!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "path_parts = parsed.path.strip('/').split('/')\n",
    "\n",
    "if len(path_parts) < 2:\n",
    "    print(\"Invalid GitHub URL! Must have org and repo in URL\")\n",
    "    sys.exit(1)\n",
    "\n",
    "org_user = path_parts[0]\n",
    "repo = path_parts[1]\n",
    "\n",
    "if not org_user or not repo:\n",
    "    print(\"Invalid GitHub URL! Must have org and repo in URL\")\n",
    "    sys.exit(1)\n",
    "\n",
    "ref = \"refs/heads/main\"\n",
    "\n",
    "if len(path_parts) >= 4 and path_parts[2].lower() == \"tree\":\n",
    "    candidate_ref = path_parts[3]\n",
    "    if len(candidate_ref) == 40 and all(c in '0123456789abcdef' for c in candidate_ref.lower()):\n",
    "        ref = candidate_ref\n",
    "    else:\n",
    "        ref = f\"refs/heads/{candidate_ref}\"\n",
    "\n",
    "repo_sub_url = f\"{org_user}/{repo}\"\n",
    "folder_url = SCRIPTS_FOLDER.strip(\"/\")\n",
    "\n",
    "create_onnx_raw_url = f\"https://raw.githubusercontent.com/{repo_sub_url}/{ref}/{folder_url}/create_onnx.py\"\n",
    "auto_install_script_raw_url = f\"https://raw.githubusercontent.com/{repo_sub_url}/{ref}/{folder_url}/autoinstallrknnapi.py\"\n",
    "create_rknn_raw_url = f\"https://raw.githubusercontent.com/{repo_sub_url}/{ref}/{folder_url}/create_rknn.py\"\n",
    "\n",
    "scriptUrls = [create_onnx_raw_url, auto_install_script_raw_url, create_rknn_raw_url]\n",
    "\n",
    "for scriptUrl in scriptUrls:\n",
    "    try:\n",
    "        subprocess.run([\"wget\", scriptUrl]).check_returncode()\n",
    "        print(f\"Successfully downloaded: {scriptUrl}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to download script from URL: {scriptUrl}\")\n",
    "        print(e)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### *Numpy Fix*\n",
    "\n",
    "Google Colab comes with an incompatible version of Numpy installed. To fix this, please run the following cells below and **restart your session** when prompted."
   ],
   "id": "d68be4aba4d3022b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%pip uninstall numpy -y\n",
    "%pip install \"numpy>=1.23.0,<2.0.0\""
   ],
   "id": "de0310a3e4401233",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 1: Convert to ONNX\n",
    "\n",
    "To convert to ONNX, simply run the `create_onnx.py` script with your model weights as shown below."
   ],
   "id": "d498ed79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where version is either yolov5, yolov8, or yolov11, and model_path is the path to your weights file (.pt)\n",
    "%run create_onnx.py --version yolov8 --model_path weights.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff07e6",
   "metadata": {},
   "source": [
    "### Step 2: Download RKNN API\n",
    "\n",
    "You can either use a script to automatically detect and install the correct RKNN API Python library for you, or install it manually.\n",
    "\n",
    "#### Automatic installation\n",
    "\n",
    "Please run the script below. If it does not work, refer to the instructions for manual installation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec11f96",
   "metadata": {},
   "outputs": [],
   "source": "%run autoinstallrknnapi.py"
  },
  {
   "cell_type": "markdown",
   "id": "8b57fe4d",
   "metadata": {},
   "source": [
    "#### Manual Installation (If Automatic Installation Fails)\n",
    "Visit the [RKNN Toolkit 2](https://github.com/airockchip/rknn-toolkit2) Github repository, then click on rknn-toolkit2, followed by packages.\n",
    "If you are running an x86_64 CPU (e.g., most Intel and AMD processors), select that option; otherwise, choose arm64 for ARM-based computers (e.g., M-series Macs or Snapdragon processors). If you're unsure which CPU you're using, check your system settings for processor architecture information.\n",
    "\n",
    "Once you've selected the correct CPU architecture, you'll see multiple packages. The file names will look something like:\n",
    "`rknn_toolkit2-2.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl`.\n",
    "The numbers after cp correspond to your Python version. For example, if you're using Python 3.10, look for a package with cp310 in the name. For Python 3.8, look for cp38; for Python 3.7, cp37, and so on.\n",
    "\n",
    "Once you've found the correct package, click the \"Raw\" button to download the .whl file. Then, run the following command in your terminal, replacing rknn_toolkit2.whl with the actual path to the file you downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install rknn_toolkit2.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1db5ef0",
   "metadata": {},
   "source": [
    "### Step 3: Convert to RKNN\n",
    "\n",
    "To get started, run the `create_rknn.py` script, replacing the arguments with your own values. Refer to the table below for detailed information on each argument’s purpose and usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e431b",
   "metadata": {},
   "source": [
    "#### Overview of the `create_rknn.py` script\n",
    "\n",
    "This script converts a YOLO ONNX model to RKNN format using a set of calibration images. It's designed to work with either:\n",
    "\n",
    "- A flat directory of images (e.g. `train/images`), **or**\n",
    "- A dataset directory containing a `data.yaml` file that defines `train`, `val`, and/or `test` folders.\n",
    "\n",
    "##### Arguments\n",
    "\n",
    "| Argument | Type | Description                                                                                                     |\n",
    "|----------|------|-----------------------------------------------------------------------------------------------------------------|\n",
    "| `--img_dir` (`-d`) | `str` (required) | Path to your image directory. This can either be a folder of images **or** a dataset folder with a `data.yaml`. |\n",
    "| `--model_path` (`-m`) | `str` (required) | Path to your YOLO ONNX model, created in Step 1.                                                                |\n",
    "| `--num_imgs` (`-ni`) | `int` (default: `300`) | Number of images to use for quantization calibration.                                                           |\n",
    "| `--disable_quantize` (`-dq`) | `bool` (default: `False`) | Set to `True` to skip quantization entirely, not recommended for performance.                                   |\n",
    "| `--rknn_output` (`-o`) | `str` (default: `out.rknn`) | File path where the final RKNN model should be saved.                                                           |\n",
    "| `--img_dataset_txt` (`-ds`) | `str` (default: `imgs.txt`) | File path to store the list of images used during quantization.                                                 |\n",
    "| `--verbose` (`-vb`) | `bool` (default: `False`) | Enable detailed logging from the RKNN API during conversion.                                                    |\n",
    "---\n",
    "\n",
    "\n",
    "##### Note\n",
    "\n",
    "This script is designed for use with [PhotonVision](https://photonvision.org), and by default sets the target platform for RKNN conversion to `RK3588`, a chipset commonly found in many variants of the Orange Pi 5 series (e.g., Orange Pi 5, 5 Pro, 5 Plus, 5 Max, etc.). You may modify the `TARGET_PLATFORM` value in the `create_onnx.py` script to match your specific hardware or deployment requirements if necessary."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Quantization Note\n",
    "\n",
    "When performing quantization, it is critical to provide representative images of the objects or scenes you are trying to detect. These images are used to calibrate the model’s internal activations and greatly influence the final performance.\n",
    "\n",
    "It is recommended to use 300–500 representative images that reflect the real-world input your model will encounter. As the old saying goes, it’s quality over quantity — having a diverse, relevant set matters more than simply having many images.\n",
    "\n",
    "Quantization will cause some loss in model accuracy. However, if your calibration images are chosen wisely, this accuracy drop should be minimal and acceptable. If the sampled images are too uniform or unrelated, your quantized model's performance may worsen significantly.\n",
    "\n",
    "The script will automatically sample representative images randomly from the provided dataset. While this usually works well, please verify that the dataset contains diverse and relevant examples of your target objects. As a reminder, the images used to quantize the model are stored in the text file specified by `--img_dataset_txt`.\n"
   ],
   "id": "5e56b2f64bf6e85f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Optional: Download a dataset from Roboflow for quantization\n",
    "\n",
    "Please run the code below to download a dataset from Roboflow if you do not have images available for quantization. You may replace the URL in quotes with a link to your own dataset.\n"
   ],
   "id": "93e0d0622df170e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%wget -O roboflow.zip \"https://universe.roboflow.com/ds/FaF3HbDmF7?key=iMoJR25O9H\" && unzip roboflow.zip -d datasets && rm roboflow.zip",
   "id": "8bf75c9dcb328c84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once your dataset is prepared, run the script below to quantize and convert the ONNX model you generated in Step 1.\n",
   "id": "81af402f3a94679a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09656dd",
   "metadata": {},
   "outputs": [],
   "source": "%run create_rknn.py --img_dir ./datasets --model_path weights.onnx"
  },
  {
   "cell_type": "markdown",
   "id": "5b3a6806",
   "metadata": {},
   "source": "And that’s it! Your RKNN model file is now ready for deployment on an Orange Pi."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
