{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63e2692b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb5367ce",
   "metadata": {},
   "source": [
    "# RKNN Conversion Guide\n",
    "\n",
    "### Before you start\n",
    "\n",
    "Before you run the scripts/python notebook from this project, it's recommended you create a separate [python virtual environment](https://docs.python.org/3/library/venv.html) so that packages installed in for the conversion process don't conflict with other packages you may already have installed\n",
    "\n",
    "### Step 1: Convert to ONNX \n",
    "\n",
    "To convert to ONNX, simply run the `create_onnx.py` script with your model weights, see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where version is either yolov5, yolov8, or yolov11, and model_path is the path to your weights file (.pt)\n",
    "%run -i create_onnx.py --version yolov8 --model_path weights.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff07e6",
   "metadata": {},
   "source": [
    "### Step 2: Download RKNN API\n",
    "You can either utilize a script to autodetect and install the correct Python library for you, or manually install it\n",
    "\n",
    "#### Automatic installation\n",
    "Simply run the `autoinstallrknnapi.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec11f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i autoinstallrknnapi.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b57fe4d",
   "metadata": {},
   "source": [
    "#### Manual installation\n",
    "##### How to find the correct link\n",
    "Go to https://github.com/airockchip/rknn-toolkit2, and click on `rknn-toolkit2`, then `packages`.\n",
    "If you are running an x86_64 CPU (e.g. most Intel and AMD CPUs) click on that, otherwise choose arm64 for ARM-based computers (e.g. M-series Macs or Snapdragon processors). If you aren't sure what CPU you are running, look up your processor architecture information from system settings.\n",
    "\n",
    "Once you have the correct CPU, you will see multiple packages. The file names will look something like `rknn_toolkit2-2.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl` for example. The numbers after CP correspond to your python version. If you have a Python version 3.10, for example, you want to download a package with cp310 in the name. For 3.8, you'd look for cp38, for 3.7 cp37, and so on.\n",
    "\n",
    "Then, once you find your desired package, locate the \"Raw\" download button, and download the package (.whl) once you do, run pip install, replacing `rknn_toolkit2.whl` with the path to the wheel file you just downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install rknn_toolkit2.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1db5ef0",
   "metadata": {},
   "source": [
    "### Step 3: Convert to RKNN\n",
    "\n",
    "Simply run the `create_rknn.py` script, replacing the arguments with your own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e431b",
   "metadata": {},
   "source": [
    "#### Overview of `create_rknn.py` script\n",
    "\n",
    "##### RKNN Conversion Script Overview\n",
    "\n",
    "This script converts a YOLO ONNX model to RKNN format using a set of calibration images. It's designed to work with either:\n",
    "\n",
    "- A flat directory of images (e.g. `train/images`), **or**\n",
    "- A dataset directory containing a `data.yaml` file that defines `train`, `val`, and/or `test` folders.\n",
    "\n",
    "You can use it from the command line or from inside a Python environment like this notebook.\n",
    "\n",
    "##### Arguments\n",
    "\n",
    "| Argument | Type | Description |\n",
    "|----------|------|-------------|\n",
    "| `--img_dir` (`-d`) | `str` (required) | Path to your image directory. This can either be a folder of images **or** a dataset folder with a `data.yaml`. |\n",
    "| `--model_path` (`-m`) | `str` (required) | Path to your YOLO ONNX model, created in Step 1. |\n",
    "| `--num_imgs` (`-ni`) | `int` (default: `300`) | Number of images to use for quantization calibration. |\n",
    "| `--disable_quantize` (`-dq`) | `bool` (default: `False`) | Set to `True` to skip quantization entirely, not recommended for performance. |\n",
    "| `--rknn_output` (`-o`) | `str` (default: `out.rknn`) | File path where the final RKNN model should be saved. |\n",
    "| `--img_dataset_txt` (`-ds`) | `str` (default: `imgs.txt`) | File path to store the list of images used during quantization. |\n",
    "| `--verbose` (`-vb`) | `bool` (default: `False`) | Enable detailed logging from RKNN during conversion. |\n",
    "---\n",
    "\n",
    "\n",
    "##### Notes\n",
    "\n",
    "As this is meant to be used with [PhotonVision](https://photonvision.org) this script only supports RK3588 (found in Orange Pi 5 models), but feel free to modify the script to suit your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09656dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i create_rknn.py --img_dir /datasets/my_imgs --model_path model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a6806",
   "metadata": {},
   "source": [
    "And that's it! You should have an RKNN model file ready to deploy on an Orange PI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
